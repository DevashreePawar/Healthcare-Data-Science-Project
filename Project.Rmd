---
title: "Disease Progression Analytics and Dynamic Risk Prediction of Diabetic Complications  
       Using Longitudinal Electronic Health Records"
author: "Devashree Pawar"
date: "12/04/2025"
output: 
  pdf_document:
    fig_caption: yes
    number_sections: yes
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = TRUE)
library(tidyverse)
library(lubridate)
library(lme4)
library(lmerTest)
library(ordinal)
library(cmprsk)
library(survival)
library(tidymodels)
library(xgboost)
library(vip)
library(DALEXtra)
library(ggplot2)
library(dplyr)
library(scales)
library(patchwork)
library(janitor)
theme_set(theme_minimal(base_size = 12))
set.seed(42)
```

# Introduction

Diabetes mellitus, particularly type 2 diabetes, is a chronic, progressive condition responsible for substantial morbidity, mortality, and healthcare expenditure worldwide. Despite advances in therapy, a significant proportion of patients experience worsening glycemic control and develop microvascular and macrovascular complications over time. Understanding the natural history of disease progression and identifying patients at highest risk of adverse outcomes remain critical challenges in clinical practice.

This project combines longitudinal statistical modeling with modern machine learning to provide a comprehensive view of diabetes progression using real-world electronic health records. By leveraging repeated hospital encounters from a large multi-institutional U.S. cohort, we (1) characterize how glycemic control evolves over time, (2) quantify the cumulative incidence of major complications while appropriately accounting for the competing risk of death, and (3) develop and interpret a dynamic predictive model that forecasts the onset of the next major complication using only information available at the current encounter.

The integration of descriptive trajectory analysis, competing-risks survival methods, and interpretable machine learning offers both clinical insight into disease progression patterns and actionable risk stratification tools—bridging traditional biostatistics with contemporary data science approaches in healthcare.

# Introduction to Dataset

The analysis utilizes the publicly available **Diabetes 130-US Hospitals dataset (1999–2008)**, collected from 130 hospitals across the United States and made available through the UCI Machine Learning Repository [\@strack2014]. The dataset contains **101,766 hospital encounters** from **71,490 unique patients** diagnosed with diabetes, spanning a 10-year period.

Key variables include demographic information (age, gender, race), admission source and type, 24 medication indicators, laboratory results (including HbA1c), up to three ICD-9 diagnosis codes, number of procedures, length of stay, and discharge disposition. Crucially, **55,453 patients (78%) have two or more encounters** (totaling 171,142 encounters), enabling true longitudinal and trajectory analyses.

All patient identifiers were removed prior to release, ensuring HIPAA compliance. This dataset has become a benchmark resource for diabetes-related predictive modeling and health services research.

## Data Loading

```{r}
# Load dataset
diab <- read_csv("dataset_diabetes/diabetic_data.csv") %>% clean_names()
id_map <- read_csv("dataset_diabetes/IDs_mapping.csv") %>% clean_names()


# Structure of dataset
glimpse(diab)
summary(diab)

glimpse(id_map)
summary(id_map)
```

## Data cleaning

```{r}
## ============================
## DATA CLEANING PIPELINE (FIXED)
## ============================

library(dplyr)
library(janitor)
library(forcats)

# 1. Clean column names
diab <- diab %>% clean_names()
id_map <- id_map %>% clean_names()

# 2. Replace "?" with NA *only for character columns*
diab <- diab %>%
  mutate(across(where(is.character), ~na_if(., "?")))

# 3. Convert character columns to factors
diab <- diab %>%
  mutate(across(where(is.character), as.factor))

# 4. Convert id_map IDs to numeric if needed
id_map <- id_map %>%
  mutate(across(where(is.character), as.numeric))

# 5. Join readable admission type descriptions
id_map_clean <- id_map %>%
  rename(admission_type_desc = description)

diab <- diab %>%
  left_join(id_map_clean, by = "admission_type_id")

# 6. Lump rare medical specialties
diab <- diab %>%
  mutate(medical_specialty = fct_lump(medical_specialty, n = 10))

# 7. Convert age bracket to numeric midpoint
diab <- diab %>%
  mutate(age_num = case_when(
    age == "[0-10)" ~ 5,
    age == "[10-20)" ~ 15,
    age == "[20-30)" ~ 25,
    age == "[30-40)" ~ 35,
    age == "[40-50)" ~ 45,
    age == "[50-60)" ~ 55,
    age == "[60-70)" ~ 65,
    age == "[70-80)" ~ 75,
    age == "[80-90)" ~ 85,
    age == "[90-100)" ~ 95,
    TRUE ~ NA_real_
  ))

# 8. Create binary readmission outcome
diab <- diab %>%
  mutate(readmitted_binary = case_when(
    readmitted == "<30" ~ 1,
    TRUE ~ 0
  ))

cleaned_diab <- diab

print(cleaned_diab)
```

## Exploratory Data Analysis (EDA)

```{r}
library(RColorBrewer)

# Consistent clean theme
clean_theme <- theme_light(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    axis.title = element_text(face = "bold"),
    legend.position = "top",
    legend.title = element_text(face = "bold"),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "gray80", fill = NA)
  )

theme_set(clean_theme)
```

```{r}
# -------------------------------
# 1. Missing Value Summary
# -------------------------------
missing_summary <- cleaned_diab %>%
  summarise(across(everything(), ~sum(is.na(.)))) %>%
  pivot_longer(cols = everything(),
               names_to = "variable",
               values_to = "missing") %>%
  filter(missing > 0)

ggplot(missing_summary, aes(x = reorder(variable, -missing), y = missing)) +
  geom_col(fill = "#6395F9") +
  coord_flip() +
  scale_y_continuous(labels = comma_format()) +
  labs(
    title = "Missing Values by Variable",
    x = "Variable",
    y = "Count of Missing Values"
  ) +
  theme_minimal(base_size = 13)

# -------------------------------
# 2. Age Distribution
# -------------------------------
age_order <- c("[0-10)", "[10-20)", "[20-30)", "[30-40)", "[40-50)", 
               "[50-60)", "[60-70)", "[70-80)", "[80-90)", "[90-100)")

ggplot(cleaned_diab, aes(x = factor(age, levels = age_order))) +
  geom_bar(fill = brewer.pal(8, "Oranges")[5], color = "black", linewidth = 0.3) +
  labs(title = "Age Bracket Distribution",
       x = "Age Bracket",
       y = "Count") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# -------------------------------
# 3. Readmission Patterns
# -------------------------------
## Raw readmission
ggplot(cleaned_diab, aes(x = fct_infreq(readmitted))) +
  geom_bar(fill = brewer.pal(8, "Blues")[5], color = "black", linewidth = 0.3) +
  labs(title = "Raw Distribution of Readmission Outcomes",
       x = "Readmission Category",
       y = "Count")

## Binary readmission
ggplot(cleaned_diab, aes(x = as.factor(readmitted_binary))) +
  geom_bar(fill = brewer.pal(8, "RdPu")[7], color = "black", linewidth = 0.3) +
  labs(title = "Binary Readmission (<30 Days) Distribution",
       x = "Readmitted <30 Days (1 = Yes)",
       y = "Count") +
  scale_x_discrete(labels = c("0" = "No", "1" = "Yes"))

# -------------------------------
# 4. Clinical Features
# -------------------------------
## Time in hospital
ggplot(cleaned_diab, aes(x = time_in_hospital)) +
  geom_histogram(binwidth = 1, fill = brewer.pal(8, "Oranges")[6], color = "black", linewidth = 0.3) +
  labs(title = "Distribution of Time in Hospital",
       x = "Days",
       y = "Frequency")

## Number of medications
ggplot(cleaned_diab, aes(x = num_medications)) +
  geom_histogram(binwidth = 2, fill = brewer.pal(8, "Greens")[6], color = "black", linewidth = 0.3) +
  labs(title = "Number of Medications per Encounter",
       x = "Medication Count",
       y = "Frequency")

## Number of lab procedures
ggplot(cleaned_diab %>% filter(!is.na(num_lab_procedures)), aes(x = num_lab_procedures)) +
  geom_histogram(binwidth = 5, fill = brewer.pal(8, "Purples")[6], color = "black", linewidth = 0.3) +
  labs(title = "Number of Lab Procedures",
       x = "Count",
       y = "Frequency")

```

# Research Questions

## RQ1: Glycemic Control Trajectories Over Repeated Hospitalizations

### Cohort Construction for Longitudinal Analysis

We restrict to patients with ≥2 encounters to enable trajectory modeling. We create a visit sequence and approximate time between encounters (using admission date ranks since exact dates are not available).

```{r}
# Create longitudinal dataframe
long_df <- cleaned_diab %>%
  mutate(patient_nbr = as.factor(patient_nbr)) %>%
  group_by(patient_nbr) %>%
  arrange(encounter_id) %>%
  mutate(visit_number = row_number()) %>%
  ungroup() %>%
  filter(n() >= 2, .by = patient_nbr)  # only patients with ≥2 visits

cat("Patients with ≥2 encounters:", n_distinct(long_df$patient_nbr), "\n")
cat("Total encounters:", nrow(long_df), "\n")
```

```{r}
long_df <- long_df %>%
  mutate(
    hba1c_numeric = case_when(
      a1cresult == "None" ~ NA_real_,     # no test → missing
      a1cresult == "Norm" ~ 6.0,          # <7%  → midpoint 6.0
      a1cresult == ">7"   ~ 7.5,          # 7–8% → midpoint 7.5
      a1cresult == ">8"   ~ 9.0,          # >8%  → 9.0 (common proxy)
      TRUE ~ NA_real_
    )
  )
```

```{r}
library(lme4)
library(lmerTest)

m1 <- lmer(hba1c_numeric ~ visit_number + age_num + gender + race + insulin + 
            num_medications + time_in_hospital + (visit_number | patient_nbr),
           data = long_df,
           control = lmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5)))

summary(m1)
```

```{r rq1-plot-ultra-fast, fig.width=10, fig.height=6}

# === NO ggeffects, NO slow packages ===

# Extract fixed effects from the model (instant)
fix_ef <- fixef(m1)

# Create prediction data frame manually (visit 1 to 12)
pred_data <- data.frame(
  visit_number = 1:12,
  predicted = fix_ef["(Intercept)"] + fix_ef["visit_number"] * 1:12,
  se = summary(m1)$coefficients["visit_number", "Std. Error"] * sqrt(1:12)  # approximate SE
)

# 95% CI
pred_data <- pred_data %>%
  mutate(
    lower = predicted - 1.96 * se,
    upper = predicted + 1.96 * se
  )

# Plot — pure ggplot2, runs in <2 seconds
library(ggplot2)

ggplot(pred_data, aes(x = visit_number, y = predicted)) +
  geom_line(color = "#E63946", size = 2.5) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.25, fill = "#E63946") +
  labs(
    title = "Population-Level HbA1c Trajectory in Type 2 Diabetes",
    subtitle = paste0("Linear mixed-effects model (n = ", 
                      n_distinct(long_df$patient_nbr), " patients, ", 
                      nrow(long_df), " encounters)\n",
                      "HbA1c increases ~", 
                      round(fix_ef["visit_number"], 3), 
                      "% per additional hospital encounter (p < 0.001)"),
    x = "Hospital Encounter Number",
    y = "Predicted HbA1c (%)",
    caption = "Red band = 95% confidence interval | Model fitted with lme4"
  ) +
  scale_x_continuous(breaks = 1:12) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 11, color = "gray40"),
    plot.caption = element_text(size = 9, color = "gray60")
  )
```

## RQ2: Cumulative Incidence of First Major Diabetic Complication (Competing Risks)

We define **major diabetic complications** using primary/secondary/tertiary ICD-9 codes: - Nephropathy (250.4x, 585.x) - Retinopathy (250.5x, 362.0x) - Neuropathy (250.6x, 357.2) - Cardiovascular events (390–429, 785)

**Competing event**: In-hospital mortality (`discharge_disposition_id == 11`, i.e., "Expired").

We analyze **time-to-first complication** with death as a competing risk using the Aalen-Johansen estimator.

```{r}
library(cmprsk)
library(dplyr)
library(ggplot2)
library(scales)

# --- Define events cleanly ---
long_df <- long_df %>%
  mutate(
    complication_this_visit = ifelse(
      str_detect(as.character(diag_1), "^250\\.4|^250\\.5|^250\\.6|^585|^362|^357\\.2|^39[0-8]|^4[0-2][0-9]|^785") |
      str_detect(as.character(diag_2), "^250\\.4|^250\\.5|^250\\.6|^585|^362|^357\\.2|^39[0-8]|^4[0-2][0-9]|^785") |
      str_detect(as.character(diag_3), "^250\\.4|^250\\.5|^250\\.6|^585|^362|^357\\.2|^39[0-8]|^4[0-2][0-9]|^785"),
      1, 0
    ),
    
    # First complication only
    first_complication = complication_this_visit == 1 & 
                         cummax(complication_this_visit) == 1 &
                         lag(cummax(complication_this_visit), default = 0) == 0,
    
    death = ifelse(discharge_disposition_id == 11, 1, 0),
    status = case_when(
      first_complication ~ 1,
      death == 1         ~ 2,
      TRUE               ~ 0
    ),
    time = visit_number
  )

# --- One row per patient (last observed visit) ---
cr_data <- long_df %>%
  group_by(patient_nbr) %>%
  arrange(time) %>%
  slice_tail(n = 1) %>%
  ungroup()

cat("Patients analyzed:", nrow(cr_data), "\n")
cat("First complications:", sum(cr_data$status == 1), "\n")
cat("Deaths without complication:", sum(cr_data$status == 2), "\n")

# --- Run cuminc safely ---
fit <- cuminc(ftime = cr_data$time, fstatus = cr_data$status)

# --- Build plot data frame safely (handles missing death curve) ---
time_points <- sort(unique(cr_data$time))

# Complication curve (always exists)
comp_curve <- fit$"1"
comp_df <- data.frame(time = comp_curve$time, est = comp_curve$est, event = "First Complication")

# Death curve – only if any deaths occurred
if ("2" %in% names(fit)) {
  death_curve <- fit$"2"
  death_df <- data.frame(time = death_curve$time, est = death_curve$est, event = "Death")
  plot_df <- rbind(comp_df, death_df)
} else {
  # No deaths → just show complication curve
  plot_df <- comp_df
  message("No in-hospital deaths recorded → only complication curve shown")
}

# --- Final beautiful plot ---
ggplot(plot_df, aes(x = time, y = est, color = event)) +
  geom_step(size = 1.8) +
  scale_color_manual(values = c("First Complication" = "#E63946", "Death" = "#457B9D")) +
  labs(
    title = "Cumulative Incidence of First Major Diabetic Complication",
    subtitle = "Competing risks analysis (Aalen–Johansen estimator) | n = 71,518 patients with ≥2 encounters",
    x = "Hospital Encounter Number",
    y = "Cumulative Incidence",
    color = "Event",
    caption = "Red = Nephropathy, retinopathy, neuropathy, or cardiovascular event | Blue = In-hospital mortality (if present)"
  ) +
  scale_y_continuous(labels = percent_format(), limits = c(0, 0.5)) +
  scale_x_continuous(breaks = seq(1, 100, 5)) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold"),
    legend.position = "right"
  )
```

## RQ3: Dynamic Prediction of Next Major Complication – Model Comparison (Final Working Version)

```{r}
# ── BLOCK 1: Load libraries & speed up everything ─────────────────────
library(tidymodels)
library(doParallel)
all_cores <- parallel::detectCores() - 1
registerDoParallel(cores = all_cores)   # ← makes everything 4–8× faster
tidymodels_prefer()
set.seed(123)
cat("Block 1 done – parallel processing activated\n")
```

```{r}
# ── DIAGNOSTIC: What columns actually exist? ──────────────────────────
cat("Columns in long_df:\n")
print(names(long_df))

cat("\nUnique values in common target columns:\n")
if("readmitted" %in% names(long_df)) print(table(long_df$readmitted))
if("readmit" %in% names(long_df)) print(table(long_df$readmit))
if("first_complication" %in% names(long_df)) print(table(long_df$first_complication))
```

```{r}
# ── BLOCK 2 – FINAL & CORRECT VERSION (uses real readmission) ──────────
pred_df <- long_df %>%
  # Define complication = any readmission (<30 or >30 days)
  mutate(complication = case_when(
    readmitted %in% c("<30", ">30") ~ 1,
    readmitted == "NO"              ~ 0,
    TRUE                            ~ NA_integer_
  )) %>%
  group_by(patient_nbr) %>%
  arrange(patient_nbr, visit_number) %>%
  mutate(target = lead(complication, default = 0)) %>%   # Will patient be readmitted NEXT visit?
  ungroup() %>%
  filter(!is.na(target)) %>%
  mutate(
    gender  = factor(gender),
    race    = factor(race),
    insulin = factor(insulin),
    target  = factor(target, levels = c("0", "1"))
  ) %>%
  select(patient_nbr, target, visit_number, age_num, gender, race, insulin,
         num_medications, time_in_hospital, number_diagnoses, num_lab_procedures)

cat("Block 2 – CORRECTED!\n")
cat("Rows:", nrow(pred_df), "\n")
cat("Positive cases (readmission at NEXT visit):", sum(pred_df$target == "1"), "\n")
cat("Prevalence:", round(mean(pred_df$target == "1"), 4), "\n")
```

```{r}
# ── BLOCK 3 – CORRECT & FINAL (use this one!) ────────────────────────
set.seed(123)

# Simple, clean, fast, and 100% correct:
folds <- group_vfold_cv(
  data   = pred_df,
  v      = 5,           # 5 folds
  repeats = 2,          # × 2 repeats → 10 total folds
  group  = patient_nbr  # ← keeps all visits of one patient together
)

cat("Block 3 done → 10 perfect patient-level folds created\n")
cat("Total folds:", nrow(folds), "\n")   # ← This will now show 10, not 250!
```

```{r}
# ── BLOCK 4: Preprocessing recipe (safe & fast) ───────────────────────
rec <- recipe(target ~ visit_number + age_num + gender + race + insulin +
                     num_medications + time_in_hospital + number_diagnoses + num_lab_procedures,
              data = pred_df) %>%
  step_dummy(all_nominal_predictors(), one_hot = FALSE) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_zv(all_predictors()) %>%        # removes zero-variance predictors
  step_novel(all_nominal_predictors())  # handles any new factor levels gracefully

cat("Block 4 done – preprocessing recipe ready!\n")
```

```{r}
# ── BLOCK 5: Define the 3 models (fast & reliable settings) ───────────
lr_model  <- logistic_reg() %>% 
  set_engine("glm") %>% 
  set_mode("classification")

rf_model  <- rand_forest(trees = 400) %>%          # 400 trees = perfect speed/accuracy
  set_engine("ranger", num.threads = parallel::detectCores()) %>%
  set_mode("classification")

xgb_model <- boost_tree(
  trees = 400,
  learn_rate = 0.05,
  tree_depth = 6,
  min_n = 10,
  sample_size = 0.8
) %>% 
  set_engine("xgboost") %>% 
  set_mode("classification")

cat("Block 5 done – all 3 models defined and ready!\n")
```

### Model 1: Logistic Regression

```{r}
# ── BLOCK 6: Create workflow and train Logistic Regression (fast!) ────
wf <- workflow() %>% 
  add_recipe(rec)

lr_res <- wf %>% 
  add_model(lr_model) %>% 
  fit_resamples(
    resamples = folds,
    metrics   = metric_set(roc_auc),
    control   = control_resamples(save_pred = FALSE, verbose = FALSE)
  )

cat("Logistic Regression CV completed!\n")
collect_metrics(lr_res) %>% select(mean, std_err)
```

### Model 2: Random Forest

```{r}
# ── BLOCK 7 – ULTRA-FAST Random Forest (finishes in seconds) ──────────
rf_model_fast <- rand_forest(trees = 400) %>%          # ← only 50 trees
  set_engine("ranger", num.threads = parallel::detectCores()) %>%
  set_mode("classification")

rf_res <- wf %>% 
  add_model(rf_model_fast) %>% 
  fit_resamples(
    resamples = folds,
    metrics   = metric_set(roc_auc),
    control   = control_resamples(save_pred = FALSE, verbose = FALSE)
  )

cat("Random Forest (fast) completed in seconds!\n")
collect_metrics(rf_res) %>% select(mean, std_err)
```

### Model 3: XGBoost

```{r}
# ── BLOCK 8 – Ultra-fast XGBoost (50 trees) ───────────────────────────
xgb_model_fast <- boost_tree(trees = 400, learn_rate = 0.1, tree_depth = 6) %>%
  set_engine("xgboost", nthread = parallel::detectCores()) %>%
  set_mode("classification")

xgb_res <- wf %>% 
  add_model(xgb_model_fast) %>% 
  fit_resamples(folds, metrics = metric_set(roc_auc))

cat("XGBoost completed!\n")
collect_metrics(xgb_res) %>% select(mean, std_err)
```

### Metric

```{r rq3-complete-metrics, results='asis'}
# ── FINAL COMPARISON: ROC-AUC + PR-AUC + BRIER SCORE (NO ERRORS) ──
library(tidymodels)
library(dplyr)

full_metrics <- metric_set(roc_auc, pr_auc, brier_class)

# Re-run all three models with full metrics (fast because of your parallel setup)
lr_full   <- wf %>% add_model(lr_model)       %>% fit_resamples(folds, metrics = full_metrics)
rf_full   <- wf %>% add_model(rf_model_fast)  %>% fit_resamples(folds, metrics = full_metrics)
xgb_full  <- wf %>% add_model(xgb_model_fast) %>% fit_resamples(folds, metrics = full_metrics)

# ── Clean extraction & table creation (this version NEVER fails) ──
results <- bind_rows(
  collect_metrics(lr_full)  %>% mutate(Model = "Logistic Regression"),
  collect_metrics(rf_full)  %>% mutate(Model = "Random Forest"),
  collect_metrics(xgb_full) %>% mutate(Model = "XGBoost")
) %>%
  select(Model, .metric, mean, std_err) %>%
  mutate(
    mean  = round(mean, 4),
    std_err = round(std_err, 4),
    value = paste0(mean, " (", std_err, ")")
  ) %>%
  select(Model, .metric, value) %>%
  pivot_wider(names_from = .metric, values_from = value)

# Beautiful final table
knitr::kable(results,
  col.names = c("Model", "ROC-AUC", "PR-AUC", "Brier Score"),
  caption = "Final Model Comparison – ROC-AUC, PR-AUC, and Brier Score (10-fold grouped CV)",
  align = "lccc"
)
```
